{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#from nlp_pred_true_comparator import compare_pred_true, clef_hipe_load_conllu_tsv_to_dict\n",
    "from nlp_pred_true_comparator import compare_pred_true, clef_hipe_load_conllu_tsv_to_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mock data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predData = [\n",
    "    {\"text\": \"hello\"},\n",
    "    {\"text\": \"world\", \"entity\": \"Jupyter, Q6\", \"info\": \"is just next to Jupyter\"},\n",
    "    {\"text\": \"my\"},\n",
    "    {\"text\": \"name\"},\n",
    "    {\"text\": \"is\"},\n",
    "    {\"text\": \"Bryan\", \"entity\": \"Bryan, Q5\", \"info\": \"is in the living room\"},\n",
    "    {\"text\": \"!\"},\n",
    "    {\"text\": \"How\"},\n",
    "    {\"text\": \"are\"},\n",
    "    {\"text\": \"you\", \"entity\": \"Youth, Q543\", \"info\": \"doesn't last long\"},\n",
    "    {\"text\": \"Doing\"},\n",
    "    {\"text\": \"Bernice\"},\n",
    "    {\"text\": \"?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trueData = [\n",
    "    {\"text\": \"hello\"},\n",
    "    {\"text\": \"world\", \"entity\": \"Earth, Q3\", \"info\": \"is in the galaxy\"},\n",
    "    {\"text\": \"my\"},\n",
    "    {\"text\": \"name\"},\n",
    "    {\"text\": \"is\"},\n",
    "    {\"text\": \"Bryan\", \"entity\": \"Bryan, Q5\", \"info\": \"is in the kitchen\"},\n",
    "    {\"text\": \"!\"},\n",
    "    {\"text\": \"How\"},\n",
    "    {\"text\": \"are\"},\n",
    "    {\"text\": \"you\"},\n",
    "    {\"text\": \"Doing\"},\n",
    "    {\"text\": \"Bernice\", \"entity\": \"Bernice, Q72\", \"info\": \"likes ice-cream\"},\n",
    "    {\"text\": \"?\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doing some comparison\n",
    "\n",
    "`compare_pred_true()` is the function to do the job:\n",
    "```python\n",
    "compare_pred_true(\n",
    "    pred_data:Sequence[dict],        # prediction as a list of tokens, each token is a dict\n",
    "    true_data:Sequence[dict],        # ground truth as a list of tokens, each token is a dict\n",
    "    text_property:str,               # the entry of the token dict containing its text content\n",
    "    compare_property:str,            # the entry containing the prediction/ground truth to compare\n",
    "    separatorsProperty:str = \"MISC\", # the entry for line separators, which contains any combination of: EndOfLine, EndOfParagraph, NoSpaceAfter\n",
    "    properties_to_display:Sequence[str] =[] # additional properties to display in additon to the pred-true comparison\n",
    ")\n",
    "```\n",
    "It shows the text and all the labelled tokens in the ground truth and predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "Tokens are highlighted as follows:\n",
       "<ul>\n",
       "<li><span style=\" color: #0f5132; background-color: #d1e7dd; font-weight:bold;\">true-positive token</span>: a correctly identified&linked token.</li>\n",
       "<li><span style=\" color: #842029; background-color: #f0a8ae; font-weight:bold;\">false-negative token</span>: a missed token, present in the ground truth but not detected in the prediction.</li>\n",
       "<li><span style=\" color: #990099; background-color: #ffccff; font-weight:bold;\">false-positive token</span>: a predicted entity in the prediction but inexistant in the ground truth. </li>\n",
       "<li><span style=\" color: #664d03; background-color: #ffe799; font-weight:bold;\">wrongly-predicted-positive token</span>: a token linked both in the prediction and ground truth, but not to the same entity.</li>\n",
       "</ul>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "Tokens are highlighted as follows:\n",
    "<ul>\n",
    "<li><span style=\" color: #0f5132; background-color: #d1e7dd; font-weight:bold;\">true-positive token</span>: a correctly identified&linked token.</li>\n",
    "<li><span style=\" color: #842029; background-color: #f0a8ae; font-weight:bold;\">false-negative token</span>: a missed token, present in the ground truth but not detected in the prediction.</li>\n",
    "<li><span style=\" color: #990099; background-color: #ffccff; font-weight:bold;\">false-positive token</span>: a predicted entity in the prediction but inexistant in the ground truth. </li>\n",
    "<li><span style=\" color: #664d03; background-color: #ffe799; font-weight:bold;\">wrongly-predicted-positive token</span>: a token linked both in the prediction and ground truth, but not to the same entity.</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_pred_true(predData, trueData, \"text\", \"entity\", \"\", [\"info\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing ground truth & predictions from conllu style tsv\n",
    "\n",
    "\n",
    "`clef_hipe_load_conllu_tsv_to_dict()` allows you to import prediction/ground truth in tsv format as spceified for the [CLEF HIPE 2020 competition](https://github.com/impresso/CLEF-HIPE-2020-scorer/blob/master/ner_evaluation/tests/data/unittest-true_bundle3_de_1.tsv):\n",
    "```python\n",
    "pred = clef_hipe_load_conllu_tsv_to_dict(filepath)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred_filepath = \"example_data/dhs-fr-pred-clef-hipe-scorer-conllu.tsv\"\n",
    "true_filepath = \"example_data/dhs-fr-true-clef-hipe-scorer-conllu.tsv\"\n",
    "\n",
    "pred_conllu = clef_hipe_load_conllu_tsv_to_dict(pred_filepath)\n",
    "true_conllu = clef_hipe_load_conllu_tsv_to_dict(true_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "compare_pred_true(pred_conllu, true_conllu, \"TOKEN\", \"NEL-LIT\", \"MISC\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0ba8461042d62ab06f66d67cc9ca318298fd283d556a98f37e80cf0f5e2bbb1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
